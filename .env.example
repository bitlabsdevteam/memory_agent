# LLM Provider Configuration
# At least one API key is required
GOOGLE_API_KEY=your_google_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
GROQ_API_KEY=your_groq_api_key_here
# Perplexity API Configuration (using official PPLX_API_KEY)
PPLX_API_KEY=your_perplexity_api_key_here

# Default provider (google_gemini, openai, groq, or perplexity)
DEFAULT_LLM_PROVIDER=google_gemini

# Model configurations
GOOGLE_MODEL=gemini-1.5-flash
OPENAI_MODEL=gpt-4o
GROQ_MODEL=deepseek-r1-distill-llama-70b
PERPLEXITY_MODEL=sonar-pro

# Agent Configuration
AGENT_TEMPERATURE=0.7
AGENT_MAX_ITERATIONS=5
AGENT_VERBOSE=True

# Memory Configuration
MEMORY_MAX_MESSAGES=20
MEMORY_OPTIMIZATION_INTERVAL=10

# Streaming Configuration
STREAMING_DELAY=0.01
STREAMING_ENABLED=True

# Flask Configuration
FLASK_ENV=development
FLASK_DEBUG=True
FLASK_HOST=0.0.0.0
FLASK_PORT=5000

# CORS Configuration
CORS_ORIGINS=*